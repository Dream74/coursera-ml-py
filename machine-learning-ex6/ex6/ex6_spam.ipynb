{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "from sklearn import svm\n",
    "\n",
    "import processEmail as pe\n",
    "import emailFeatures as ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "np.set_printoptions(formatter={'float': '{: 0.6f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk, nltk.stem.porter\n",
    "\n",
    "\n",
    "def get_vocab_list():\n",
    "    vocab_dict = {}\n",
    "    with open('vocab.txt') as f:\n",
    "        for line in f:\n",
    "            (val, key) = line.split()\n",
    "            vocab_dict[int(val)] = key\n",
    "\n",
    "    return vocab_dict\n",
    "\n",
    "\n",
    "def process_email(email_contents):\n",
    "    vocab_list = get_vocab_list()\n",
    "\n",
    "    word_indices = np.array([], dtype=np.int64)\n",
    "\n",
    "    # ===================== Preprocess Email =====================\n",
    "\n",
    "    email_contents = email_contents.lower()\n",
    "\n",
    "    email_contents = re.sub('<[^<>]+>', ' ', email_contents)\n",
    "\n",
    "    # Any numbers get replaced with the string 'number'\n",
    "    email_contents = re.sub('[0-9]+', 'number', email_contents)\n",
    "\n",
    "    # Anything starting with http or https:// replaced with 'httpaddr'\n",
    "    email_contents = re.sub('(http|https)://[^\\s]*', 'httpaddr', email_contents)\n",
    "\n",
    "    # Strings with \"@\" in the middle are considered emails --> 'emailaddr'\n",
    "    email_contents = re.sub('[^\\s]+@[^\\s]+', 'emailaddr', email_contents)\n",
    "\n",
    "    # The '$' sign gets replaced with 'dollar'\n",
    "    email_contents = re.sub('[$]+', 'dollar', email_contents)\n",
    "\n",
    "    # ===================== Tokenize Email =====================\n",
    "\n",
    "    # Output the email\n",
    "    # print('==== Processed Email ====')\n",
    "\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "    # print('email contents : {}'.format(email_contents))\n",
    "\n",
    "    tokens = re.split('[@$/#.-:&*+=\\[\\]?!(){\\},\\'\\\">_<;% ]', email_contents)\n",
    "\n",
    "    idx_list = []\n",
    "    for token in tokens:\n",
    "        token = re.sub('[^a-zA-Z0-9]', '', token)\n",
    "        token = stemmer.stem(token)\n",
    "\n",
    "        if len(token) < 1:\n",
    "            continue\n",
    "\n",
    "        # ===================== Your Code Here =====================\n",
    "        # Instructions : Fill in this function to add the index of token to\n",
    "        #                word_indices if it is in the vocabulary. At this point\n",
    "        #                of the code, you have a stemmed word frome email in\n",
    "        #                the variable token. You should look up token in the\n",
    "        #                vocab_list. If a match exists, you should add the\n",
    "        #                index of the word to the word_indices nparray.\n",
    "        #                Concretely, if token == 'action', then you should\n",
    "        #                look up the vocabulary list the find where in vocab_list\n",
    "        #                'action' appears. For example, if vocab_list[18] == 'action'\n",
    "        #                then you should add 18 to the word_indices array.\n",
    "\n",
    "\n",
    "\n",
    "        # ==========================================================\n",
    "        for idx, s in vocab_list.items():\n",
    "            if s == token:\n",
    "                idx_list.append(idx)\n",
    "\n",
    "    word_indices = np.array(idx_list)\n",
    "    # print('==================')\n",
    "\n",
    "    return word_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing sample email (emailSample1.txt) ...\n"
     ]
    }
   ],
   "source": [
    "# ===================== Part 1: Email Preprocessing =====================\n",
    "# To use an SVM to classify emails into spam v. non-spam, you first need to\n",
    "# convert each email into a vector of features. In this part, you will\n",
    "# implement the preprocessing steps for each email. You should\n",
    "# complete the code in processEmail.py to produce a word indices vector\n",
    "# for a given email.\n",
    "\n",
    "print('Preprocessing sample email (emailSample1.txt) ...')\n",
    "\n",
    "file_contents = open('emailSample1.txt', 'r').read()\n",
    "word_indices = process_email(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Indices: \n",
      "[  86  916  794 1077  883  370 1699  790 1822 1831  883  431 1171  794\n",
      " 1002 1893 1364  592 1676  238  162   89  688  945 1663 1120 1062 1699\n",
      "  375 1162  479 1893 1510  799 1182 1237  810 1895 1440 1547  181 1699\n",
      " 1758 1896  688 1676  992  961 1477   71  530 1699  531]\n"
     ]
    }
   ],
   "source": [
    "# Print stats\n",
    "print('Word Indices: ')\n",
    "print(word_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def email_features(word_indices):\n",
    "    # Total number of words in the dictionary\n",
    "    n = 1899\n",
    "\n",
    "    # You need to return the following variables correctly.\n",
    "    # Since the index of numpy array starts at 0, to align with the word indices we make n + 1 size array\n",
    "    features = np.zeros(n + 1)\n",
    "\n",
    "    # ===================== Your Code Here =====================\n",
    "    # Instructions : Fill in this function to return a feature vector for the\n",
    "    #                given email (word_indices). To help make it easier to\n",
    "    #                process the emails, we have already pre-processed each\n",
    "    #                email and converted each word in the email into an index in\n",
    "    #                a fixed dictionary (of 1899 words). The variable\n",
    "    #                word_indices contains the list of indices of the words\n",
    "    #                which occur in one email.\n",
    "    #\n",
    "    #                Concretely, if an email has the text:\n",
    "    #\n",
    "    #                   The quick brown fox jumped over the lazy dog.\n",
    "    #\n",
    "    #                Then, the word_indices vector for this text might look\n",
    "    #                like:\n",
    "    #\n",
    "    #                   60  100   33  44  10      53  60  58  5\n",
    "    #\n",
    "    #                where, we have mapped each word onto a number, for example:\n",
    "    #\n",
    "    #                   the     --  60\n",
    "    #                   quick   --  100\n",
    "    #                   ...\n",
    "    #\n",
    "    #                Your task is take one such word_indices vector and construct\n",
    "    #                a binary feature vector that indicates whether a particular\n",
    "    #                word occurs in the email. That is, features[i] = 1 when word i\n",
    "    #                is present in the email. Concretely, if the word 'the' (say,\n",
    "    #                index 60) appears in the email, then features[60] = 1. The feature\n",
    "    #                vector should look like:\n",
    "    #\n",
    "    #                features = [0, 0, 0, 0, 1, 0, 0, 0, ... 0, 0, 0, 1, ... 0, 0, 0, 1, 0]\n",
    "    #\n",
    "    #\n",
    "\n",
    "    for idx in word_indices:\n",
    "        features[idx] = 1\n",
    "    # ==========================================================\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Features from sample email (emailSample1.txt) ... \n"
     ]
    }
   ],
   "source": [
    "# ===================== Part 2: Feature Extraction =====================\n",
    "# Now, you will convert each email into a vector of features in R^n.\n",
    "# You should complete the code in emailFeatures.py to produce a feature\n",
    "# vector for a given mail\n",
    "\n",
    "print('Extracting Features from sample email (emailSample1.txt) ... ')\n",
    "\n",
    "# Extract features\n",
    "features = email_features(word_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of feature vector: 1900\n",
      "Number of non-zero entries: 45\n"
     ]
    }
   ],
   "source": [
    "# Print stats\n",
    "print('Length of feature vector: {}'.format(features.size))\n",
    "print('Number of non-zero entries: {}'.format(np.flatnonzero(features).size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear SVM (Spam Classification)\n",
      "(this may take 1 to 2 minutes)\n"
     ]
    }
   ],
   "source": [
    "# ===================== Part 3: Train Linear SVM for Spam Classification =====================\n",
    "# In this section, you will train a linear classifier to determine if an\n",
    "# email is Spam or Not-spam.\n",
    "\n",
    "# Load the Spam Email dataset\n",
    "# You will have X, y in your environment\n",
    "data = scio.loadmat('spamTrain.mat')\n",
    "X = data['X']\n",
    "y = data['y'].flatten()\n",
    "\n",
    "print('Training Linear SVM (Spam Classification)')\n",
    "print('(this may take 1 to 2 minutes)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 99.825\n"
     ]
    }
   ],
   "source": [
    "c = 0.1\n",
    "clf = svm.SVC(c, kernel='linear')\n",
    "clf.fit(X, y)\n",
    "\n",
    "p = clf.predict(X)\n",
    "\n",
    "print('Training Accuracy: {}'.format(np.mean(p == y) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the trained linear SVM on a test set ...\n",
      "Test Accuracy: 98.9\n"
     ]
    }
   ],
   "source": [
    "# ===================== Part 4: Test Spam Classification =====================\n",
    "# After training the classifier, we can evaluate it on a test set. We have\n",
    "# included a test set in spamTest.mat\n",
    "\n",
    "# Load the test dataset\n",
    "data = scio.loadmat('spamTest.mat')\n",
    "Xtest = data['Xtest']\n",
    "ytest = data['ytest'].flatten()\n",
    "\n",
    "print('Evaluating the trained linear SVM on a test set ...')\n",
    "\n",
    "p = clf.predict(Xtest)\n",
    "\n",
    "print('Test Accuracy: {}'.format(np.mean(p == ytest) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1190  297 1397 ... 1764 1665 1560]\n",
      "otherwis (0.500614)\n",
      "clearli (0.465916)\n",
      "remot (0.422869)\n",
      "gt (0.383622)\n",
      "visa (0.367710)\n",
      "base (0.345064)\n",
      "doesn (0.323632)\n",
      "wife (0.269724)\n",
      "previous (0.267298)\n",
      "player (0.261169)\n",
      "mortgag (0.257298)\n",
      "natur (0.253941)\n",
      "ll (0.253467)\n",
      "futur (0.248297)\n",
      "hot (0.246404)\n"
     ]
    }
   ],
   "source": [
    "# ===================== Part 5: Top Predictors of Spam =====================\n",
    "# Since the model we are training is a linear SVM, we can inspect the w\n",
    "# weights learned by the model to understand better how it is determining\n",
    "# whether an email is spam or not. The following code finds the words with\n",
    "# the highest weights in the classifier. Informally, the classifier\n",
    "# 'thinks' that these words are the most likely indicators of spam.\n",
    "#\n",
    "\n",
    "vocab_list = pe.get_vocab_list()\n",
    "indices = np.argsort(clf.coef_).flatten()[::-1]\n",
    "print(indices)\n",
    "\n",
    "for i in range(15):\n",
    "    print('{} ({:0.6f})'.format(vocab_list[indices[i]], clf.coef_.flatten()[indices[i]]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
